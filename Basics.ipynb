{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes \n",
    "\n",
    "In this project, we study the practical side of Naive Bayes algorithm by building a spam filter for SMS messages.\n",
    "\n",
    "Our first task is to teach the computer how to classify messages. To do this, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "The dataset used in this project can be downloaded directly from [this link](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "Let's start by reading in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datapoints are separated by '/t',the dataset doesn't have a header, assign column labels \n",
    "sms_data = pd.read_csv(\"SMSSpamCollection\", sep = \"\\t\", header = None, names = ['Label', 'SMS'])\n",
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sms_data.shape)\n",
    "sms_data[\"Label\"].value_counts(dropna=False, normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the frequency distribution of \"Label\" column in the dataset, we see that about 86.6% of the messages are ham (\"ham\" means non-spam) and the remaining 13.4% of the messages are spam.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into 'training set' and 'test set'\n",
    "\n",
    "For this project, our goal is to create a spam filter that classifies new messages with an accuracy greater than 80%.\n",
    "\n",
    "Hence, once we build our spam filter, we'll need to test how good it is with classifying new messages. To test the spam filter, we are first going to split our dataset into two categories:\n",
    "\n",
    "- A **training set**, which we'll use to \"train\" the computer on how to classify messages \n",
    "- A **test set**, which we'll use to test how well the spam filter works in classifying new messages\n",
    "\n",
    "\n",
    "We are going to keep 80% of our dataset for training, and 20% for testing (we want to train the algorithm on as much data as possible, but we also want to have enough test data). The dataset has 5,572 messages, which means that:\n",
    "\n",
    "- The training set will have 4,458 messages (about 80% of the dataset).\n",
    "- The test set will have 1,114 messages (about 20% of the dataset)\n",
    "\n",
    "Let's start by:\n",
    "\n",
    "- Randomizing the entire dataset to ensure that spam and ham messages are spread properly throughout the dataset.\n",
    "- Split the randomized dataset into a training and a test set, with the training set accounting for 80% of the dataset and the remaining 20% of the dataset as test set.\n",
    "- Find the percentage of spam and ham in both the training and the test set to check if they are similar to what we have in the full dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "(4458, 2)\n",
      "\n",
      "\n",
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "\n",
      "(1114, 2)\n",
      "\n",
      "\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use the parameter frac = 1 to randomize the entire dataset\n",
    "# Use the random_state = 1 parameter to make sure our results are reproducible\n",
    "randomized_data = sms_data.sample(frac = 1, random_state = 1)\n",
    "print(randomized_data.shape)\n",
    "#split the data into training and test set.\n",
    "training_data = randomized_data[:4458].reset_index(drop = True)\n",
    "test_data = randomized_data[4458:].reset_index(drop = True)\n",
    "\n",
    "#checking the percentage of spam and ham in both the training and the test set. \n",
    "print(training_data.shape)\n",
    "print(\"\\n\")\n",
    "print(training_data[\"Label\"].value_counts(normalize = True)*100)\n",
    "print(\"\\n\")\n",
    "print(test_data.shape)\n",
    "print(\"\\n\")\n",
    "print(test_data[\"Label\"].value_counts(normalize = True)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the frequency distributions of both training dataset and test dataset, we see that the distribution of messages across spam and non-spam in both the datasets is similar to that of the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data cleaning to compute the probabilities\n",
    "\n",
    "When a new message comes in, the Naive Bayes algorithm will make the classification based on the computed probabilities. \n",
    "\n",
    "To calculate all these probabilities, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need.\n",
    "\n",
    "To make the calculations easier, we want bring the data to the following format:\n",
    "\n",
    "|   | Label | secret | prize | claim | now | coming | to | my| party | winner|\n",
    "| --- | --- | ------ | ------ | ----- | ---- | ---- | ---- | ---- | ----- | ----- |\n",
    "| 0  | spam  | 2 | 2 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| 1  | ham  | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 0 |\n",
    "\n",
    "- The SMS column doesn't exist anymore.\n",
    "- Instead, the SMS column is replaced by a series of new columns, where each column represents a unique word from the vocabulary.\n",
    "- Each row describes a single message. \n",
    "- For instance,first row corresponds to the message \"SECRET PRIZE! CLAIM SECRET PRIZE NOW!!\", and it has the values spam, 2, 2, 1, 1, 0, 0, 0, 0, 0. These values tell us that:\n",
    " * The message is spam.\n",
    " * The word \"secret\" occurs two times inside the message.\n",
    " * The word \"prize\" occurs two times inside the message.\n",
    " * The word \"claim\" occurs one time inside the message.\n",
    " * The word \"now\" occurs one time inside the message.\n",
    " * The words \"coming\", \"to\", \"my\", \"party\", and \"winner\" occur zero times inside the message.\n",
    "- All words in the vocabulary are in lower case, so \"SECRET\" and \"secret\" come to be considered to be the same word.\n",
    "- Punctuation is not taken into account anymore. \n",
    "\n",
    "Let's begin the data cleaning process by removing the punctuation and bringing all the words to lower casee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the punctuation from the SMS column\n",
    "# Transform every letter in every word to lower case\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "training_data['SMS'] = training_data['SMS'].str.replace(r'\\W', ' ')\n",
    "training_data['SMS'] = training_data['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the vocabulary\n",
    "\n",
    "Let's create a vocabulary for the messages in the training dataset.  The vocabulary is a Python list containing all the unique words across all messages, where each word is represented as a string. We begin by:\n",
    "\n",
    "- Transforming each message from the SMS column into a list of words by splitting the string at the space character\n",
    "- Create a vocabulary list and remove the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['confused', 'ger', 'edwards', 'depressed', 'key']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming each message from the SMS column into a list by splitting the string at the space character\n",
    "training_data[\"SMS\"] = training_data[\"SMS\"].str.split()\n",
    "\n",
    "#Initiate an empty list named vocabulary\n",
    "vocabulary = []\n",
    "\n",
    "#Appending all words across all messages to the list vocabulary \n",
    "for message in training_data[\"SMS\"]:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "#Removing the duplicates from the vocabulary list \n",
    "vocabulary = list(set(vocabulary))\n",
    "print(len(vocabulary))\n",
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the data transformation\n",
    "\n",
    "We're now going to use the vocabulary to make the data transformation we need. \n",
    "\n",
    "Eventually, we're going to create a new DataFrame in the format:\n",
    "\n",
    "|   | Label | secret | prize | claim | now | coming | to | my| party | winner|\n",
    "| --- | --- | ------ | ------ | ----- | ---- | ---- | ---- | ---- | ----- | ----- |\n",
    "| 0  | spam  | 2 | 2 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| 1  | ham  | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize a dictionary named word_counts_per_sms, where each key is a unique word (a string) from the vocabulary\n",
    "#and each value is a list of the length of training set, where each element in the list is a 0\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_data['SMS']) \n",
    "                       for unique_word in vocabulary}\n",
    "\n",
    "#Loop over every message in training_data \n",
    "#Use enumerate to get both index and message\n",
    "#Loop over each word in the message and \n",
    "#Increment the counter for the word in the dictionary by 1 in the place of its index in the list\n",
    "for index,message in enumerate(training_data['SMS']):\n",
    "    for word in message:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting word_counts_per_sms dictionary into word_counts dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "                         ...                          zogtorius  zouk  zyada  \\\n",
       "0                        ...                                  0     0      0   \n",
       "1                        ...                                  0     0      0   \n",
       "2                        ...                                  0     0      0   \n",
       "3                        ...                                  0     0      0   \n",
       "4                        ...                                  0     0      0   \n",
       "\n",
       "   é  ú1  ü  〨ud  鈥  Label                                                SMS  \n",
       "0  0   0  0    0  0    ham                  [yep, by, the, pretty, sculpture]  \n",
       "1  0   0  0    0  0    ham  [yes, princess, are, you, going, to, make, me,...  \n",
       "2  0   0  0    0  0    ham                    [welp, apparently, he, retired]  \n",
       "3  0   0  0    0  0    ham                                           [havent]  \n",
       "4  0   0  2    0  0    ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate the new word_counts dataframe with the training_data dataframe to also add 'Label' and 'SMS' columns \n",
    "new_data = pd.concat([word_counts, training_data], axis = 1)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7785)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the spam filter\n",
    "\n",
    "The Naive Bayes algorithm will need to know the probability values of the two equations below to be able to classify new messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "Also, to calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we need to use these equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "The terms P(Spam) and P(Ham), N<sub>Spam</sub>, N<sub>Ham</sub>, N<sub>Vocabulary</sub> will have the same value for every new message\n",
    "\n",
    "- N<sub>Spam</sub> is equal to the total number of words in all the spam messages.\n",
    "- N<sub>Ham</sub> is equal to the total number of words in all the non-spam messages.\n",
    "- We'll also use Laplace smoothing and set alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8654104979811574\n",
      "0.13458950201884254\n",
      "7783\n"
     ]
    }
   ],
   "source": [
    "#Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "# Calculating P(Spam) and P(Ham)\n",
    "p_ham = new_data[\"Label\"].value_counts(normalize=True)['ham']\n",
    "p_spam = new_data[\"Label\"].value_counts(normalize=True)['spam']\n",
    "print(p_ham)\n",
    "print(p_spam)\n",
    "\n",
    "#Calculating N_vocabulary\n",
    "n_vocab = len(vocabulary)\n",
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5\n",
       "1     9\n",
       "2     4\n",
       "3     1\n",
       "4    26\n",
       "Name: no_of_words, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column 'no_of_words' and assign the number of words in each message to the column \n",
    "new_data[\"no_of_words\"] = new_data.iloc[:,:-2].sum(axis = 1)\n",
    "new_data[\"no_of_words\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in all the spam messages is 15190\n",
      "Number of words in all the ham messages is 57237\n"
     ]
    }
   ],
   "source": [
    "#Calculating N_Spam and N_Ham\n",
    "n_spam = new_data.loc[new_data['Label'] == 'spam','no_of_words'].sum()\n",
    "n_ham = new_data.loc[new_data['Label'] == 'ham','no_of_words'].sum()\n",
    "print(\"Number of words in all the spam messages is {0}\".format(n_spam))\n",
    "print(\"Number of words in all the ham messages is {0}\".format(n_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating parameters\n",
    "\n",
    "The parameters P(wi|Spam) and P(wi|Ham) vary depending on the word, but the probability for each individual word is constant for every new message. Let's now calculate all the parameters using the equations below:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize two dictionaries, where each key-value pair is a unique word (from our vocabulary) represented as a string, and the value is 0. \n",
    "#spam_dict dictionary to store the parameters for P(wi|Spam), and ham_dict for P(wi|Ham)\n",
    "spam_dict = {unique_word: 0 for unique_word in vocabulary}\n",
    "ham_dict = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "#Splitting the cleaned data into spam_data and ham_data \n",
    "spam_data = new_data[new_data[\"Label\"] == 'spam']\n",
    "ham_data = new_data[new_data[\"Label\"] == 'ham']\n",
    "\n",
    "#calculating the number of times each word occurs across all spam messages\n",
    "for unique_word in spam_dict:\n",
    "    spam_dict[unique_word] = spam_data[unique_word].sum()\n",
    "\n",
    "#calculating the number of times each word occurs across all ham messages\n",
    "for unique_word in ham_dict:\n",
    "    ham_dict[unique_word] = ham_data[unique_word].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculating the paramters i.e, the conditional probability for each word \n",
    "for unique_word in vocabulary:\n",
    "    #Calculating P(wi|Spam)\n",
    "    numerator_1 = spam_dict[unique_word] + alpha\n",
    "    denominator_1 = (n_spam + alpha * n_vocab)\n",
    "    spam_dict[unique_word] = numerator_1/denominator_1\n",
    "    \n",
    "    #Calculating P(wi|Ham)\n",
    "    numerator_2 = ham_dict[unique_word] + alpha\n",
    "    denominator_2 = (n_ham + alpha * n_vocab)\n",
    "    ham_dict[unique_word] = numerator_2/denominator_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              spam\n",
      "confused  0.000044\n",
      "ger       0.000044\n",
      "edwards   0.000044\n",
      "offense   0.000044\n",
      "what      0.000653\n",
      "               ham\n",
      "confused  0.000031\n",
      "ger       0.000031\n",
      "edwards   0.000031\n",
      "offense   0.000031\n",
      "what      0.003476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>confused</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ger</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edwards</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offense</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.003476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spam       ham\n",
       "confused  0.000044  0.000031\n",
       "ger       0.000044  0.000031\n",
       "edwards   0.000044  0.000031\n",
       "offense   0.000044  0.000031\n",
       "what      0.000653  0.003476"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting spam_dict into a dataframe\n",
    "spam_parameters = pd.DataFrame.from_dict(spam_dict,\n",
    "                                   orient='index')\n",
    "spam_parameters = spam_parameters.rename(columns={0: 'spam'})\n",
    "print(spam_parameters.head())\n",
    "\n",
    "#Converting ham_dict into a dataframe\n",
    "ham_parameters = pd.DataFrame.from_dict(ham_dict,\n",
    "                                   orient='index')\n",
    "ham_parameters = ham_parameters.rename(columns={0: 'ham'})\n",
    "print(ham_parameters.head())\n",
    "\n",
    "#Concatenating two dataframes into parameters dataframe\n",
    "parameters = pd.concat([spam_parameters, ham_parameters], axis = 1)\n",
    "parameters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a new message\n",
    "\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "- Takes in as input a new message (w1, w2, ..., wn)\n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "- If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "- If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "- If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in parameters.index:\n",
    "            p_spam_given_message = p_spam_given_message * parameters.loc[word,'spam']\n",
    "            p_ham_given_message = p_ham_given_message * parameters.loc[word,'ham']\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "ham\n"
     ]
    }
   ],
   "source": [
    "print(classify(\"WINNER!! This is the secret code to unlock the money: C3421.\"))\n",
    "\n",
    "print(classify(\"Sounds good, Tom, then see u there\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the spam filter's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new column 'predicted' in the test dataset with the value returned by the classify function\n",
    "test_data['predicted'] = test_data['SMS'].apply(classify)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "98.74326750448833\n"
     ]
    }
   ],
   "source": [
    "total = test_data.shape[0]\n",
    "mask = (test_data['Label'] == test_data['predicted'])\n",
    "test_correct = mask.sum()\n",
    "print(test_correct)\n",
    "accuracy = (test_correct/total) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is close to 98.74%, which is really good. Our spam filter looked at 1,114 messages that it hasn't seen in training, and classified 1,100 correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
